{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08cb09cd-d45b-4ebb-8286-f37bb585b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text extraction...\n",
      "Text extraction complete. First 500 characters: Cuneyt Gurcan Akcora\n",
      "University of Central Florida\n",
      "\n",
      "BA1-419, 12744 Pegasus Drive, Orlando, Florida, 32816\n",
      "Web: cakcora.github.io\n",
      "\n",
      "E-mail: cuneyt.akcora@ucf.edu\n",
      "\n",
      "Research Interests\n",
      "\n",
      "• Explainable artiﬁcial intelligence\n",
      "\n",
      "• Data Science on complex networks, large scale graph analysis\n",
      "\n",
      "• Nonparametric statistics, bootstrap on graphs\n",
      "\n",
      "• Deep learning and graph mining on Blockchain networks\n",
      "\n",
      "• Machine learning for privacy and security research on online social networks\n",
      "\n",
      "• Topological data analysis\n",
      "\n",
      "Wo\n",
      "Conference Publications section found.\n",
      "* GOttack: Universal Adversarial Attacks on Graph Neural Networks via Graph Orbits\n",
      "\n",
      "Learning\n",
      "* Chainlet Orbits: Topological Address Embedding for the Bitcoin Blockchain\n",
      "* On the Impact of the Lightning Network on Bitcoin Transaction Fees and Network Value\n",
      "* GraphPulse: Topological representations for temporal graph property prediction\n",
      "* Smart Vectorizations for Single and Multiparameter Persistence\n",
      "* Reduction Algorithms for Persistence Diagrams of Networks: CoralTDA and PrunIT\n",
      "* BitcoinHeist: Topological Data Analysis for Ransomware Payment Detection on the Bit-\n",
      " coin Blockchain\n",
      "* N\n",
      "* Attacklets: Modeling High Dimensionality in Real World Cyberattacks\n",
      "* Forecasting Bitcoin Price with Graph Chainlets\n",
      "* Temporal rules discovery for web data cleaning\n",
      "* Discovering trust patterns in ego networks\n",
      "* Risks of friendships on social networks\n",
      "* Network and proﬁle based measures for user similarities on social networks\n",
      "* Building virtual communities on top of online social networks\n",
      "* Crowd-sourced sensing and collaboration using Twitter\n"
     ]
    }
   ],
   "source": [
    "# Summary: Text Extraction from PDF files (Resume Example)\n",
    "\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "import os\n",
    "\n",
    "# Path to the provided PDF file \n",
    "pdf_path = r\"C:\\Documents\\AkcoraCV.pdf\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"Error: File {pdf_path} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Extract text from the PDF\n",
    "print(\"Starting text extraction...\")\n",
    "all_text = extract_text(pdf_path)\n",
    "print(f\"Text extraction complete. First 500 characters: {all_text[:500]}\")\n",
    "\n",
    "# Define regex pattern to locate \"Peer Reviewed Conference Papers\" section\n",
    "conference_pattern = r\"Peer Reviewed Conference Papers(.*?)Journal Publications\"\n",
    "match = re.search(conference_pattern, all_text, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    conference_text = match.group(1).strip()\n",
    "    print(\"Conference Publications section found.\")\n",
    "else:\n",
    "    print(\"Conference Publications section not found.\")\n",
    "    exit()\n",
    "\n",
    "# Split the text by common paper separators (cid:5 or bullet points)\n",
    "papers = re.split(r'(?:\\(cid:5\\)|cid:5|•|\\n\\*)', conference_text)\n",
    "\n",
    "# Process each paper to extract only the title\n",
    "titles = []\n",
    "for paper in papers:\n",
    "    if not paper.strip():\n",
    "        continue\n",
    "        \n",
    "    # Clean up the paper text - remove line breaks that might split titles\n",
    "    paper = re.sub(r'\\n(?=[a-z])', ' ', paper.strip())\n",
    "    \n",
    "    # Extract the title (everything up to the first author or year indicator)\n",
    "    # Titles typically end when we see patterns like initials or years\n",
    "    title_match = re.match(r'([^,]+?)(?=\\s+[A-Z]\\.\\s*[A-Z]\\.|\\s+[A-Z]\\.|\\s+\\d{4}|\\s+\\(\\d{4}\\))', paper)\n",
    "    \n",
    "    if title_match:\n",
    "        title = title_match.group(1).strip()\n",
    "        # Remove any trailing periods that aren't part of abbreviations\n",
    "        title = re.sub(r'\\.$', '', title)\n",
    "        titles.append(title)\n",
    "\n",
    "# Print titles in the required format\n",
    "for title in titles:\n",
    "    if title:  # Skip empty titles\n",
    "        print(f\"* {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092ca18-dab1-4a53-90b5-964f7251c96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
